---
title: "KF-summaries"
author: "Kevin Robb"
date: "9/8/2020"
output:
  html_document:
    df_print: paged
    fig_caption: yes
    highlights: pygments
    number_sections: no
    theme: cerulean
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Summary of Kalman Filter

## Introduction & Terms

I wrote this while going through the tutorial at [kalmanfilter.net](kalmanfilter.net).

A _Kalman Filter_ is a mathematical model which uses measurements and estimations (as well as the uncertainty in each) to produce accurate guesses of hidden variables which can include position, velocity, temperature, or whatever is being measured. The _KF_ can be used in a wide variety of applications, and this tutorial focuses on target tracking as the primary example. This involves simple position measurements of an airplane moving linearly either towards or away from the sensor. Some other examples discussed are determining the temperature of a fish tank or the weight of something on a scale using many repeated measurements. The original paper by Rudolf Kalman was published in 1960 and described a recursive solution to the discrete-data linear filtering problem.


A _KF_ works by using a set of five equations, each serving a purpose as follows in this section. These equations together with continued input from sensors produce a fairly accurate estimate of the current state of the system as well as a prediction of the _System State_ at the next timestep. These future predictions are also used to take the next measurement (like making sure the radar hits the plane) and continue the _KF_ process. As such, there is a requirement to have a prediction algorithm, called a _Dynamic Model_. For tracking a moving object, this can simply involve Newtonâ€™s equations of motion. The _Dynamic Model_ (or _State Space Model_) takes the current state as input and gives the predicted next state as output. 

Uncertainty in the sensor data is called _Measurement Noise_, and uncertainty in the _Dynamic Model_ (due to not accounting for wind, turbulence, etc) is called _Process Noise_. The _Kalman Filter_ is a prediction algorithm which takes into account both of these forms of noise in addition to the simple _Dynamic Model_. The _Kalman Filter_ assumes normal distribution of measurement errors. The normal distribution (or Gaussian) is described by the probability density function (PDF):
	$$
	  f(x;\mu,\sigma^2)=\frac{1}{\sqrt{2 \pi \sigma^2}}e^{\frac{-(x-\mu)^2}{2 \sigma^2}}
	$$
![_Basic math concepts related to measurement distribution and uncertainty._](images/kf-meas-distr.png){width=75%}


## Simple Example and the State Update Equation

This example features measuring the weight of a gold bar several times with a scale, and using these measurements to estimate the actual weight of the gold bar (assuming there is no systematic bias in the scale). The _Dynamic Model_ here is very simple, since we expect the weight of the gold bar to stay constant. 

![_Example set of measurements, with true value constant._](images/kf-weight-ex.png){width=75%}

We could find the true value by taking many measurements and averaging them, so we use this fact for our estimations. 

$$
  \hat{x}_{N,N} = \frac{1}{N}(z_1 + z_2 + ... + z_N) = \frac{1}{N} \sum^N_{n=1}(z_n) \textrm{ ,}
$$
where:

 * $x$ is the true weight value (which we have no way of knowing exactly)
 * $x_{n+1,n} = x_{n,n}$, because the dynamic model is constant.
 * $z_n$ is the measurement at timestep $n$
 * $\hat{x}_{n,n}$ is the estimate of $x$ made at timestep $n$ after taking the measurement $z_n$
 * $\hat{x}_{n,n-1}$ is the previous estimate made at timestep $n-1$ after taking the measurement $z_{n-1}$
 * $\hat{x}_{n+1,n}$ is the estimate of the next state made at timestep $n$ after taking the measurement $z_n$. This is a predicted state.

Our estimate for $x$ will build on all previous estimates, slowly converging towards the true value. Rather than keeping track of all previous measurements, we will simply use the most recent estimate and the current measurement. We can derive the equation
$$
  \hat{x}_{N,N} = \hat{x}_{N,N-1} + \frac{1}{N}(z_N - \hat{x}_{N,N-1}) \textrm{ ,}
$$
which is called the _State Update Equation_. This is one of the five KF equations. The term $(z_N - \hat{x}_{N,N-1})$ is a measurement residual called the _innovation_ which contains the new information.

The factor $\frac{1}{N}$ changes with each iteration, and is called the _Kalman Gain_. It is denoted $K_n$. We can rewrite the _State Update Equation_ as
$$
  \hat{x}_{N,N} = (K_N) z_N + (1 - K_N) \hat{x}_{N,N-1} \textrm{ .}
$$
The _Kalman Gain_ will not always be in this form, but here it means that after $n$ becomes large enough, the measurement term is negligible and we can stop.

This process follows the procedure described in the following flow chart:

![_Process followed as the Kalman Filter runs._](images/kf-process-chart.png){width=75%}

An initial estimate is required to kick off the KF process, but it need not be very precise. Following this procedure yields something like the following:

![_Results of running the KF for ten timesteps._](images/kf-process-results.png){width=75%}



### Side Note

The _State Update Equation_ is very similar to something I used in my research project in 2018. The agents in my population would evolve their _Learning Rate_, $L$, over the course of generations, and use this as the _Kalman Gain_ in this general form to update their expected values for the rewards of each of the three possible choices. Similarly, it took into account the most recent reward and the aggregate expected reward, just as above 


## Non-Constant Example and the State Extrapolation Equation

This example features an airplane moving horizontally at constant velocity away from a range detector. The _Dynamic Model_ for this situation is no longer constant, and requires two equations of motion:
$$
  x_{n+1} = x_n + \dot{x}_n \Delta t \\
  \dot{x}_{n+1} = \dot{x}_n
$$
where $\Delta t$ is the interval between measurements, and $\dot{x}_n$ is the velocity at timestep $n$. This system of equations making up the _Dynamic Model_ is called a _State Extrapolation Equation_ (or _Transition Equation_ / _Prediction Equation_), and is the second of the five _Kalman Filter_ equations. This is because it extrapolates the current state to the next state as a prediction. Note that in this case there are two equations needed because we must predict the change in both the position and the velocity. Note that this example assumes our radar measures range and uses that to calculate velocity, rather than measuring velocity directly.

### The $\alpha$ - $\beta$ Filter

This is very similar to the previous example, but we have two equations and two variables to predict which form the _State Update Equation_ for this example. These are also called the _$\alpha$ - $\beta$ track  update equations._

$$
  \hat{\dot{x}}_{n,n} = \hat{\dot{x}}_{n,n-1} + \beta (\frac{z_n - \hat{x}_{n,n-1}}{\Delta t}) \\
  \hat{x}_{n,n} = \hat{x}_{n,n-1} + \alpha (z_n - \hat{x}_{n,n-1})
$$
Here $\beta$ represents whether we think a difference between expectation and measurement was caused by radar imprecision or a change in the velocity of the aircraft. A much higher difference than we'd expect given the radar precision would elicit a high $\beta$, allowing our predicted velocity to change. If the difference is below our radar precision threshold, then we set a low $\beta$ since the velocity probably hasn't changed, and the difference can be attributed to radar measurement error.

The value of $\alpha \in [0,1]$ is a set value that depends on our radar measurement precision (high $\alpha$ for high precision). Unlike the _Kalman Gain_ in the basic _State Update Equation_ in our first example, $\alpha$ does not change as the number of timesteps increases.

![_Results of the $\alpha$ - $\beta$ filter. The estimates converge towards the true value_](images/kf-alpha-beta-result.png){width=75%}

This also works for a plane with constant acceleration, and therefore changing velocity:

```{r, echo=FALSE, out.width="49%", out.height="20%", fig.cap="Estimates for range and velocity over many timesteps.", fig.show='hold', fig.align='center'}
knitr::include_graphics(c("images/kf-ab-accel-range.png","images/kf-ab-accel-vel.png"))
```

We can see that the position is estimated fairly well, but the velocity estimates tend to be off persistently. This gap is called a _lag error_. 

### The $\alpha$ - $\beta$ - $\gamma$ Filter

The addition of the $\gamma$ term essentially allows more equations to be used. We increase our _Dynamic Model_ to three kinematic equations, accounting now for acceleration in addition to position and velocity. The _State Update Equation_ then includes three equations, one for each coefficient. This process follows the previous very similarly, with the following graphical results:

```{r, echo=FALSE, out.width="30%", out.height="15%", fig.cap="Estimates for range, velocity, and acceleration over many timesteps.", fig.show='hold', fig.align='center'}
knitr::include_graphics(c("images/kf-abg-range.png","images/kf-abg-vel.png","images/kf-abg-accel.png"))
```

We can see this eliminates the lag error in velocity, but the estimate for acceleration is terrible. If we care about predicting the acceleration, we can add a fourth equation to account for jerk, which will improve the acceleration plot. We can do this type of thing until all the variables we care about are accurately tracked and predicted, which usually will not go beyond position, velocity, and perhaps acceleration.

Some examples of $\alpha$ - $\beta$ - $\gamma$ filters include the _Kalman Filter_, _Extended Kalman Filter_, _Unscented Kalman Filter_, _Cubature Kalman Filter_, _Particle Filter_, and _Bayes Filter_.

## 1D Kalman Filter w/o Process Noise

### Measurement and Estimate Uncertainties

We will begin to include uncertainties in our calculations.

The difference between a measurement and the true value (such as when weighing a gold bar in our first example) is called a _measurement error_. These errors are random, and can be described by a Gaussian with variance $\sigma^2$. This variance of the measurement errors is called the _measurement uncertainty_ and is also denoted by $r$. This value can be obtained from the measurement device's manufacturer or derived via calibration.
$$
  r = \sigma_{meas}^2
$$

The difference between the estimate and the true value is called an _estimate error_. This error becomes smaller as we take more measurements, tending towards zero as the estimates converge on the true value. We don't know this value, but we can estimate the _uncertainty in estimate_, denoted by $p$. 

### The Kalman Gain Equation in 1D

The $\alpha$ - $\beta$ (- $\gamma$) parameters can be calculated dynamically for each filter iteration. These are called the _Kalman Gain_, denoted by $K_n$. The _Kalman Gain Equation_ is the third _Kalman Filter_ equation we have seen thus far:

$$
  K_n = \frac{\textrm{Uncertainty in Estimate}}{\textrm{Uncertainty in Estimate + Uncertainty in Measurement}} \\
  = \frac{p_{n,n-1}}{p_{n,n-1} + r_n}
$$
where:

 - $p_{n,n-1}$ is the extrapolated estimate uncertainty
 - $r_n$ is the measurement uncertainty
 - $0 \leq K_n \leq 1$

This brings us back to the generalized form of the _State Update Equation_ which we wrote previously:
$$
  \hat{x}_{n,n} = (K_n) z_n + (1 - K_n) \hat{x}_{n,n-1}
$$
This has some effects:

 - When the measurement uncertainty is very large compared to the estimate uncertainty, $K_n$ is close to zero, giving very little weight to the measurements.
 - When the measurement uncertainty is very small (the measurements are very precise), $K_n$ is close to one, giving a lot of weight to the measurements and very little weight to the estimates.
 - When both uncertainties are about even, $K_n$ is close to 0.5.

The _Kalman Gain_ tells us how much we want to change the aggregate estimate when given a new measurement.

### The Covariance Update Equation in 1D

We update the estimate uncertainty via the _Covariance Update Equation_:
$$
  p_{n,n} = (1 - K_n) p_{n,n-1}
$$
where:

 - $K_n$ is the Kalman Gain
 - $p_{n,n-1}$ is the estimate uncertainty that was calculated during the previous filter iteration
 - $p_n,n$ is the estimate uncertainty of the current state
 
Since $K_n \leq 1$, we can see that $p$ gets smaller with each filter iteration. When the measurement uncertainty is higher, it will take longer for $p$ to converge towards zero.

This is the fourth _Kalman Filter_ equation.

### The Covariance Extrapolation Equation in 1D

Like state extrapolation, the estimate uncertainty extrapolation is done with the _Dynamic Model_ equations. The _Covariance Extrapolation Equation_ thus depends on the situation & its _Dynamic Model_. This is the fifth _Kalman Filter Equation_. 

For our first example, measuring a gold bar of constant weight with a scale, the _Dynamic Model_ is constant, so the _Covariance Extrapolation Equation_ would be 
$$
  p_{n+1,n} = p_{n,n}
$$
where $p$ is the estimate uncertainty for the weight.

For the second example of radar tracking an aircraft moving linearly at constant velocity, the _Dynamic Model_ is
$$
  \hat{x}_{n+1,n} = \hat{x}_{n,n} + \hat{\dot{x}}_{n,n} \Delta t \\
  \hat{\dot{x}}_{n+1,n} = \hat{\dot{x}}_{n,n}
$$
so the _Covariance Extrapolation Equation_ is
$$
  p^x_{n+1,n} = p^x_{n,n} + \Delta t^2 * p^v_{n,n} \\
  p^v_{n+1,n} = p^v_{n,n}
$$
where:

 - $p^x$ is the position estimate uncertainty
 - $p^v$ is the velocity estimate uncertainty

### Putting it All Together

TO-DO
